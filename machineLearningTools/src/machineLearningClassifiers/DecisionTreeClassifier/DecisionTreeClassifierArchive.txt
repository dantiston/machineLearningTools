package machineLearningClassifiers;

import static machineLearningTools.MLMath.informationGain;

import java.io.BufferedWriter;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.OutputStreamWriter;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Set;

import machineLearningTools.ConfusionMatrix;
import machineLearningTools.Data;
import machineLearningTools.Document;
import machineLearningTools.MachineLearningClassifier;
import machineLearningTools.Rule;
import machineLearningTools.Tree;

/**
 * DecisionTreeClassifier
 *
 * DecisionTreeClassifier has methods for training, classifying,
 *   and testing, as well as generating output documents for these <br>
 *
 * Input: <br>
 * 	Data: training, testing <br>
 * 	Parameters: <br>
 * 		maxDepth: maximum depth to recurse down <br>
 *   	minGain: minimum information gain at each node to
 *   		continue recursion <br>
 *   	modelFile: filename to output model file containing
 *   		paths to leaves with associated labels->probabilities <br>
 *   	sysOutput: filename to output system output containing
 *   		a sorted list of instances with label to probabilities <br>
 * Output: <br>
 * 	stdout: confusion matrices over training and testing data <br>
 * 	Files: <br>
 * 		modelFile: file containing paths to leaves with
 * 			number of instances at leaf and number of instances
 * 			per label at leaf as probabilities <br>
 *   	sysOutput: file containing a sorted list of instances
 *   		with label to probabilities mappings <br><br>
 *
 * This classifier implements the MachineLearningClassifier interface
 *
 * @author T.J. Trimble
 */
public class DecisionTreeClassifier implements MachineLearningClassifier {
	//// Variables
	// Parameters
	private int maxDepth;
	private Double minGain;
	private String sysOutputFile;
	private String modelFile;

	// Core Values
	private Data trainingData;
	private Tree tree;
	private ArrayList<Rule> rules;

	// Output values
	private BufferedWriter modelOutput;
	private BufferedWriter sysOutput;

	/**
	 * Construct a new DecisionTreeClassifier object to do classification.
	 *
	 * @param maxDepth must be greater than or equal to 1
	 * @param minGain must be greater than or equal to 0
	 * @param sysOutputFileName
	 * @param modelFileName
	 * @author T.J. Trimble
	 */
	public DecisionTreeClassifier(int maxDepth, Double minGain, String sysOutputFileName, String modelFileName) throws IllegalArgumentException {
		if (minGain == null || sysOutputFileName == null || modelFileName == null) {
			throw new NullPointerException("DecisionTreeClassifier constructor received a null argument;");
		}
		if (maxDepth < 1 || minGain < 0) {
			throw new IllegalArgumentException("DecisionTreeClassifier constructor parameter preconditions violated;");
		}
		// Test if files exist
//		if ((!new File(sysOutputFileName).isFile()) || (!new File(modelFileName).isFile())) {
//			throw new IllegalArgumentException("DecisionTreeClassifier sysOutput file or model file not found;");
//		}
		this.maxDepth = maxDepth;
		this.minGain = minGain;
		this.sysOutputFile = sysOutputFileName;
		this.modelFile = modelFileName;
	}

	@Override
	public void train(String trainingDataFileName) {
		// Load data
		if (trainingDataFileName == null) {
			throw new NullPointerException();
		}
		this.trainingData = new Data(trainingDataFileName);
		// Recurse to build decision tree
		this.tree = this.calculateTree(this.trainingData.getIDs(), 1);
		// Calculate rules and save to object
		this.rules = this.tree.getRules();
		// Create model file
		try {
			this.modelOutput = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(this.modelFile), "utf-8"));
			this.writeModelFile(this.modelOutput);
			this.modelOutput.close();
		}
		catch (IOException e) {
			System.err.println("Error writing model file.");
			e.printStackTrace();
		}
	}

	@Override
	public void test(String testingDataFileName, String testingLabel) {
		if (testingDataFileName == null || testingLabel == null) {
			throw new NullPointerException();
		}
		Data testData = new Data(testingDataFileName);
		Data systemOutput = this.classify(testData);
		this.outputResults(systemOutput, testingLabel);
	}

	/**
	 * For training, first calculate the top node entropy, then
	 * calculate the tree with the *TOP* parent set to null
	 * @param docIDs
	 * @param depth
	 * @return
	 */
	private Tree calculateTree(Set<Integer> docIDs, int depth) {
		if (docIDs == null) {
			throw new NullPointerException();
		}
		Double topEnt = this.trainingData.getEntropy(docIDs);
		return this.calculateTree(docIDs, depth, topEnt, null, "*TOP*");
	}

	/**
	 * For training, calculate the decision tree by splitting
	 * on the feature resulting in the highest information gain
	 *
	 * @param docIDs
	 * @param depth must be >= 0
	 * @param topEnt must be >= 0
	 * @param parent *TOP* node is null
	 * @param nodeFeature
	 * @return
	 */
	private Tree calculateTree(Set<Integer> docIDs, int depth, Double topEnt, Tree parent, String nodeFeature) throws IllegalArgumentException {
		if (docIDs == null || topEnt == null || nodeFeature == null) {
			throw new NullPointerException();
		}
		if (depth < 0 || topEnt < 0) {
			throw new IllegalArgumentException();
		}

		//// Initializations
		// Initialize this node
		Tree result = new Tree(nodeFeature, docIDs, this.trainingData);
		if (docIDs.size() <= 1 || depth >= this.maxDepth) {
			return result;
		}
		// If not single leaf and haven't gotten to maxDepth...
		Double bestGain = 0.0d;
		String bestFeature = "";
		Double bestWithEnt = 0.0d;
		Double bestWithOutEnt = 0.0d;
		HashSet<Integer> documentsWithSplit = null;
		HashSet<Integer> documentsWithOutSplit = null;
		// Initializations
		HashSet<Integer> documentsWithFeature;
		HashSet<Integer> documentsWithOutFeature;
		Tree withChild;
		Tree withOutChild;
		Double withEnt;
		Double withOutEnt;
		Double gain;

		//// Loop through features to get best
		// Get features from these documents
		HashSet<String> features = new HashSet<String>();
		for (Integer id: docIDs) {
			features.addAll(this.trainingData.getFeatures(id));
		}

		//// Split documents based on feature
		// Loop through each feature in document set to
		// find the best split
		for (String feature: features) {
			// Split documents based on feature
			documentsWithFeature = new HashSet<Integer>();
			documentsWithOutFeature = new HashSet<Integer>();
			for (Integer id: docIDs) {
				if (this.trainingData.getDoc(id).contains(feature)) {
					documentsWithFeature.add(id);
				}
				else {
					documentsWithOutFeature.add(id);
				}
			}

			// Calculate entropy and information gain
			withEnt = this.trainingData.getEntropy(documentsWithFeature);
			withOutEnt = this.trainingData.getEntropy(documentsWithOutFeature);
			gain = informationGain(withEnt, documentsWithFeature.size(), withOutEnt, documentsWithOutFeature.size(), topEnt);

			// Store values for best information gain
			if (gain > bestGain) {
				bestGain = gain;
				bestFeature = feature;
				documentsWithSplit = documentsWithFeature;
				documentsWithOutSplit = documentsWithOutFeature;
				bestWithEnt = withEnt;
				bestWithOutEnt = withOutEnt;
			}
		}

		if (bestGain == 0.0d || bestGain < this.minGain) {
			return result;
		}

		// Recurse down each path
		String notFeature = "!"+bestFeature;
		withChild = this.calculateTree(documentsWithSplit, depth+1, bestWithEnt, result, bestFeature);
		withOutChild = this.calculateTree(documentsWithOutSplit, depth+1, bestWithOutEnt, result, notFeature);
		if ((withChild != null) && (withOutChild != null)) {
			result.addChild(withChild);
			result.addChild(withOutChild);
		}
		return result;
	}

	/**
	 * Evaluate each document in testingData to match with
	 * a rule from the training and assign a label
	 * @param testingData
	 * @return
	 */
	@Override
	public Data classify(Data testingData) {
		if (testingData == null) {
			throw new NullPointerException();
		}
		if (this.rules == null) {
			System.err.println("Classify called before training completed;");
			throw new NullPointerException();
		}
		// Classify data
		for (Document document: testingData.getDocs()) {
			for (Rule rule: this.rules) {
				if (rule.accepts(document)) {
					document.setSysOutput(rule);
					break; // out of rules
				}
			}
		}
		return testingData;
	}

	/**
	 * @param testResult
	 * @throws IOException
	 */
	@Override
	public void outputResults(Data testResult, String trainOrTest) {
		if (testResult == null || trainOrTest == null) {
			throw new NullPointerException();
		}
		try {
			// Open the output files
			this.sysOutput = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(this.sysOutputFile), "utf-8"));

			// Create system output file
			this.writeSysOutput(testResult, this.sysOutput);

			// Close the output files
			this.sysOutput.close();
		} catch (IOException e) {
			System.err.println("Failed to write results. Check your system output filename and system setup.");
			e.printStackTrace();
		}

		// Output confusion matrix to stdout
		System.out.println(new ConfusionMatrix(testResult, trainOrTest));
	}

	/**
	 * @param modelOutput
	 * @throws IOException
	 */
	public void writeModelFile(BufferedWriter modelOutput) throws IOException {
		if (modelOutput == null) {
			throw new NullPointerException();
		}
		if (this.rules == null) {
			System.err.println("writeModelFile called before training completed;");
			System.exit(-1);
		}
		Integer counter = 1;
		for (Rule rule: this.rules) {
			modelOutput.write(String.format("%s %s %s", rule.toString(), rule.getDocCount(), rule.getFormattedProbabilities()));
			if (counter < this.rules.size()) {
				modelOutput.write(String.format("%n"));
			}
		}

	}

	/**
	 * @param testResult
	 * @param sysOutput
	 * @throws IOException
	 */
	public void writeSysOutput(Data testResult, BufferedWriter sysOutput) throws IOException {
		if (testResult == null || sysOutput == null) {
			throw new NullPointerException();
		}
		// instanceID true_label class1 prob1 class2 prob2 ...
		Integer counter = 1;
		for (Integer docID: testResult.getIDs()) {
			sysOutput.write(String.format("Document:%s %s", docID, testResult.getDoc(docID).getLabel()));
			// Print out labels by sorted probabilities
			for (String label: testResult.getAllLabels()) {
				sysOutput.write(String.format(" %s %f", label, testResult.getDoc(docID).getLabelProb(label)));
			}
			if (counter < testResult.getIDs().size()) {
				sysOutput.write(String.format("%n"));
			}
			counter++;
		}
	}

	/**
	 * Returns this Classifier object's Data object <br>
	 * For testing.
	 *
	 * @return this Classifier object's Data object
	 */
	Data getData() {
		return this.trainingData;
	}

	/**
	 * Returns this Classifier object's Tree object <br>
	 * For testing.
	 *
	 * @return this Classifier object's Tree object
	 */
	Tree getTree() {
		return this.tree;
	}

	/**
	 * Returns this Classifier object's list of Rule objects <br>
	 * For testing.
	 *
	 * @return this Classifier object's list of Rule objects
	 */
	ArrayList<Rule> getRules() {
		return this.rules;
	}

}

/**
 * Runnable helper for multi-threaded DecisionTreeClassifier
 *
 * TODO: Integrate this with DecisionTreeClassifier
 *
 * @author T.J. Trimble
 */
class DecisionTreeClassifierHelper implements Runnable {

	/**
	 * DecisionTreeClassifierHelper#run() spawns threads running
	 * calculateTree() to build a Decision Tree in a multi-threaded
	 * fashion
	 *
	 * @see java.lang.Runnable#run()
	 */
	@Override
	public void run() {

	}

}